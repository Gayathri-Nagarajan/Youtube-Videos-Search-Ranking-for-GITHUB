runApp('R/Mini Projects/Youtube Videos Search Ranking')
View(temp)
runApp('R/Mini Projects/Youtube Videos Search Ranking')
runApp('R/Mini Projects/Youtube Videos Search Ranking')
runApp('R/Mini Projects/Youtube Videos Search Ranking')
runApp('R/Mini Projects/Youtube Videos Search Ranking')
#references 1-https://github.com/cosmoduende/r-youtube-personal-history-analysis/blob/master/main.R
#2-http://www.danimadrid.net/coding/scraping_youtube_without_api.html
#3-https://www.storybench.org/how-to-download-youtube-data-in-r-using-tuber-and-purrr/
library(SentimentAnalysis)
#INteract with Youtube API
library(stringr)
library(rvest)
library(tidyverse)
library(jsonlite)
library(tidytext)
library(lubridate)
library(wordcloud)
library(httr)
library(ggplot2)
library(wordcloud2)
library(RCurl)
library(curl)
library(pbapply)
library(ggthemes)
#https://developers.google.com/youtube/v3/getting-started
#key= AIzaSyCIbzRxoTgnbfd4soC6mjLb3SEGqSST9O4
############################################
#Get all the playlists in a channel
#Hebbars Kitchen
library(tuber)
library(magrittr) # Pipes %>%, %T>% and equals(), extract().
library(tidyverse) # all tidyverse packages
library(purrr) # package for iterating/extracting data
#Every day this creates a .httr.oauth file
#Delete it and run it to authenticate
#when running this, I gave #1 save local
#and will need to delete every day.else give #2.
client_id <- "446814024594-hq17q4lg0dvbhr0slkdl2f6gsddkm1os.apps.googleusercontent.com"
client_sec <- "HvyQgmJVlTSKXMTggSe97GZT"
yt_oauth(client_id, client_sec)
s_text="Panner Butter Masala"
res <- yt_search(s_text)
res <- head(res,20)
#print("iam here 1")
#https://cran.r-project.org/web/packages/tuber/vignettes/tuber-ex.html
my_df<- data.frame(vid=character(),
viewcount=integer(),
likecount=integer(),
dislikecount=integer(),
favouritecount=integer(),
commentcount=integer())
my_df["title"] <- as.character()
my_df["description"] <- as.character()
my_df["publishTime"] <- as.character()
my_df["channelTitle"] <- as.character()
#my_df["thumbnails.high.url"] <- as.character()
my_df["link"] <- as.character()
my_df["overall_positive_score"]<- as.integer()
my_df["overall_negative_score"]<- as.integer()
my_df["overall_neutral_score"]<- as.integer()
my_df["viewcount"]<- as.integer()
my_df["likecount"]<- as.integer()
my_df["dislikecount"]<- as.integer()
#print("after my_df")
# url = paste(URL_base, allids[[i]], URL_details, URL_key, sep = "")
for (i in 1:nrow(res)) {
#For each video, get the rating,view count
# print(paste(i,"in loop"))
v_id <-  res[i,"video_id"]
video_stats <- get_stats(video_id=v_id)
my_df[i,1:6] <- data.frame(matrix(unlist(video_stats), nrow=1, byrow=TRUE),stringsAsFactors=FALSE)
my_df[i,"title"] <- res[i,"title"]
my_df[i,"description"] <- res[i,"description"]
my_df[i,"channelId"] <- res[i,"channelId"]
my_df[i,"publishTime"] <- res[i,"publishTime"]
my_df[i,"channelTitle"] <- res[i,"channelTitle"]
#my_df[i,"thumbnails.high.url"] <- res[i,"thumbnails.high.url"]
#my_df[i,"link"] <-paste("https://www.youtube.com/watch?v=",v_id,sep="")
}
# url = paste(URL_base, allids[[i]], URL_details, URL_key, sep = "")
nrow(res)
v_id <-  res[1,"video_id"]
video_stats <- get_stats(video_id=v_id)
get_stats(v_id)
?get_stats()
getwd()
s_text="Panner Butter Masala"
res <- yt_search(s_text)
client_id <- "446814024594-hq17q4lg0dvbhr0slkdl2f6gsddkm1os.apps.googleusercontent.com"
client_sec <- "HvyQgmJVlTSKXMTggSe97GZT"
yt_oauth(client_id, client_sec)
s_text="Panner Butter Masala"
res <- yt_search(s_text)
res <- head(res,20)
#print("iam here 1")
#https://cran.r-project.org/web/packages/tuber/vignettes/tuber-ex.html
my_df<- data.frame(vid=character(),
viewcount=integer(),
likecount=integer(),
dislikecount=integer(),
favouritecount=integer(),
commentcount=integer())
my_df["title"] <- as.character()
my_df["description"] <- as.character()
my_df["publishTime"] <- as.character()
my_df["channelTitle"] <- as.character()
#my_df["thumbnails.high.url"] <- as.character()
my_df["link"] <- as.character()
my_df["overall_positive_score"]<- as.integer()
my_df["overall_negative_score"]<- as.integer()
my_df["overall_neutral_score"]<- as.integer()
my_df["viewcount"]<- as.integer()
my_df["likecount"]<- as.integer()
my_df["dislikecount"]<- as.integer()
#print("after my_df")
# url = paste(URL_base, allids[[i]], URL_details, URL_key, sep = "")
nrow(res)
for (i in 1:nrow(res)) {
#For each video, get the rating,view count
# print(paste(i,"in loop"))
v_id <-  res[i,"video_id"]
video_stats <- get_stats(video_id=v_id)
my_df[i,1:6] <- data.frame(matrix(unlist(video_stats), nrow=1, byrow=TRUE),stringsAsFactors=FALSE)
my_df[i,"title"] <- res[i,"title"]
my_df[i,"description"] <- res[i,"description"]
my_df[i,"channelId"] <- res[i,"channelId"]
my_df[i,"publishTime"] <- res[i,"publishTime"]
my_df[i,"channelTitle"] <- res[i,"channelTitle"]
#my_df[i,"thumbnails.high.url"] <- res[i,"thumbnails.high.url"]
#my_df[i,"link"] <-paste("https://www.youtube.com/watch?v=",v_id,sep="")
}
#Convert thumbnail to vid links
#https://www.youtube.com/watch?v=pjJgCXx_FRk
View(my_df)
client_id <- "446814024594-hq17q4lg0dvbhr0slkdl2f6gsddkm1os.apps.googleusercontent.com"
client_sec <- "HvyQgmJVlTSKXMTggSe97GZT"
yt_oauth(client_id, client_sec,token='')
client_id <- "446814024594-hq17q4lg0dvbhr0slkdl2f6gsddkm1os.apps.googleusercontent.com"
client_sec <- "HvyQgmJVlTSKXMTggSe97GZT"
yt_oauth(client_id, client_sec,token='')
s_text="Panner Butter Masala"
res <- yt_search(s_text)
res <- head(res,20)
#print("iam here 1")
#https://cran.r-project.org/web/packages/tuber/vignettes/tuber-ex.html
my_df<- data.frame(vid=character(),
viewcount=integer(),
likecount=integer(),
dislikecount=integer(),
favouritecount=integer(),
commentcount=integer())
my_df["title"] <- as.character()
my_df["description"] <- as.character()
my_df["publishTime"] <- as.character()
my_df["channelTitle"] <- as.character()
#my_df["thumbnails.high.url"] <- as.character()
my_df["link"] <- as.character()
my_df["overall_positive_score"]<- as.integer()
my_df["overall_negative_score"]<- as.integer()
my_df["overall_neutral_score"]<- as.integer()
my_df["viewcount"]<- as.integer()
my_df["likecount"]<- as.integer()
my_df["dislikecount"]<- as.integer()
#print("after my_df")
# url = paste(URL_base, allids[[i]], URL_details, URL_key, sep = "")
nrow(res)
for (i in 1:nrow(res)) {
#For each video, get the rating,view count
# print(paste(i,"in loop"))
v_id <-  res[i,"video_id"]
video_stats <- get_stats(video_id=v_id)
my_df[i,1:6] <- data.frame(matrix(unlist(video_stats), nrow=1, byrow=TRUE),stringsAsFactors=FALSE)
my_df[i,"title"] <- res[i,"title"]
my_df[i,"description"] <- res[i,"description"]
my_df[i,"channelId"] <- res[i,"channelId"]
my_df[i,"publishTime"] <- res[i,"publishTime"]
my_df[i,"channelTitle"] <- res[i,"channelTitle"]
#my_df[i,"thumbnails.high.url"] <- res[i,"thumbnails.high.url"]
#my_df[i,"link"] <-paste("https://www.youtube.com/watch?v=",v_id,sep="")
}
#Convert thumbnail to vid links
#https://www.youtube.com/watch?v=pjJgCXx_FRk
#convert to numeric
my_df <- transform(my_df, viewcount = as.numeric(viewcount),
likecount = as.numeric(likecount),
dislikecount=as.numeric(dislikecount))
#Order desc by viewcount,likecount, asc dislikecount
my_df <-my_df[order(-my_df[,2],-my_df[,3],my_df[,4]),]
#my_df <- my_df[,-c(8,9,10)]
#
# v_id<-  res[1,"video_id"]
# video_stats <- get_stats(video_id=v_id)
#
# my_df[1,] <- data.frame(matrix(unlist(video_stats), nrow=1, byrow=TRUE),stringsAsFactors=FALSE)
#
# video_stats
#View(my_df)
#nrow(res)
my_df
res <- yt_search(s_text)
#references 1-https://github.com/cosmoduende/r-youtube-personal-history-analysis/blob/master/main.R
#2-http://www.danimadrid.net/coding/scraping_youtube_without_api.html
#3-https://www.storybench.org/how-to-download-youtube-data-in-r-using-tuber-and-purrr/
library(SentimentAnalysis)
#INteract with Youtube API
library(stringr)
library(rvest)
library(tidyverse)
library(jsonlite)
library(tidytext)
library(lubridate)
library(wordcloud)
library(httr)
library(ggplot2)
library(wordcloud2)
library(RCurl)
library(curl)
library(pbapply)
library(ggthemes)
#https://developers.google.com/youtube/v3/getting-started
#key= AIzaSyCIbzRxoTgnbfd4soC6mjLb3SEGqSST9O4
############################################
#Get all the playlists in a channel
#Hebbars Kitchen
library(tuber)
library(magrittr) # Pipes %>%, %T>% and equals(), extract().
library(tidyverse) # all tidyverse packages
library(purrr) # package for iterating/extracting data
#Every day this creates a .httr.oauth file
#Delete it and run it to authenticate
#when running this, I gave #1 save local
#and will need to delete every day.else give #2.
client_id <- "446814024594-hq17q4lg0dvbhr0slkdl2f6gsddkm1os.apps.googleusercontent.com"
client_sec <- "HvyQgmJVlTSKXMTggSe97GZT"
yt_oauth(client_id, client_sec,token='')
s_text="Panner Butter Masala"
res <- yt_search(s_text)
setwd("~/R/Mini Projects/Youtube Videos Search Ranking")
client_id <- "446814024594-hq17q4lg0dvbhr0slkdl2f6gsddkm1os.apps.googleusercontent.com"
client_sec <- "HvyQgmJVlTSKXMTggSe97GZT"
yt_oauth(client_id, client_sec,token='')
s_text="Panner Butter Masala"
res <- yt_search(s_text)
res <- head(res,50)
#print("iam here 1")
#https://cran.r-project.org/web/packages/tuber/vignettes/tuber-ex.html
my_df<- data.frame(vid=character(),
viewcount=integer(),
likecount=integer(),
dislikecount=integer(),
favouritecount=integer(),
commentcount=integer())
my_df["title"] <- as.character()
my_df["description"] <- as.character()
my_df["publishTime"] <- as.character()
my_df["channelTitle"] <- as.character()
#my_df["thumbnails.high.url"] <- as.character()
my_df["link"] <- as.character()
my_df["overall_positive_score"]<- as.integer()
my_df["overall_negative_score"]<- as.integer()
my_df["overall_neutral_score"]<- as.integer()
my_df["viewcount"]<- as.integer()
my_df["likecount"]<- as.integer()
my_df["dislikecount"]<- as.integer()
#print("after my_df")
for (i in 1:nrow(res)) {
#For each video, get the rating,view count
# print(paste(i,"in loop"))
v_id <-  res[i,"video_id"]
video_stats <- get_stats(video_id=v_id)
my_df[i,1:6] <- data.frame(matrix(unlist(video_stats), nrow=1, byrow=TRUE),stringsAsFactors=FALSE)
my_df[i,"title"] <- res[i,"title"]
my_df[i,"description"] <- res[i,"description"]
my_df[i,"channelId"] <- res[i,"channelId"]
my_df[i,"publishTime"] <- res[i,"publishTime"]
my_df[i,"channelTitle"] <- res[i,"channelTitle"]
#my_df[i,"thumbnails.high.url"] <- res[i,"thumbnails.high.url"]
#my_df[i,"link"] <-paste("https://www.youtube.com/watch?v=",v_id,sep="")
}
#convert to numeric
my_df <- transform(my_df, viewcount = as.numeric(viewcount),
likecount = as.numeric(likecount),
dislikecount=as.numeric(dislikecount))
#Order desc by viewcount,likecount, asc dislikecount
my_df <-my_df[order(-my_df[,2],-my_df[,3],my_df[,4]),]
#my_df <- my_df[,-c(8,9,10)]
#
# v_id<-  res[1,"video_id"]
# video_stats <- get_stats(video_id=v_id)
#
# my_df[1,] <- data.frame(matrix(unlist(video_stats), nrow=1, byrow=TRUE),stringsAsFactors=FALSE)
#
# video_stats
#View(my_df)
#nrow(res)
View(my_df)
shiny::runApp()
setDT(my_df)
saveRDS(my_df, "data/dt.RDS")
runApp()
res <- yt_search(s_text)
#https://cran.r-project.org/web/packages/tuber/vignettes/tuber-ex.html
my_df<- data.frame(vid=character(),
viewcount=integer(),
likecount=integer(),
dislikecount=integer(),
favouritecount=integer(),
commentcount=integer())
my_df["title"] <- as.character()
my_df["description"] <- as.character()
my_df["publishTime"] <- as.character()
my_df["channelTitle"] <- as.character()
#my_df["thumbnails.high.url"] <- as.character()
my_df["link"] <- as.character()
my_df["overall_positive_score"]<- as.integer()
my_df["overall_negative_score"]<- as.integer()
my_df["overall_neutral_score"]<- as.integer()
my_df["viewcount"]<- as.integer()
my_df["likecount"]<- as.integer()
my_df["dislikecount"]<- as.integer()
for (i in 1:nrow(res)) {
#For each video, get the rating,view count
# print(paste(i,"in loop"))
v_id <-  res[i,"video_id"]
video_stats <- get_stats(video_id=v_id)
my_df[i,1:6] <- data.frame(matrix(unlist(video_stats), nrow=1, byrow=TRUE),stringsAsFactors=FALSE)
my_df[i,"title"] <- res[i,"title"]
my_df[i,"description"] <- res[i,"description"]
my_df[i,"channelId"] <- res[i,"channelId"]
my_df[i,"publishTime"] <- res[i,"publishTime"]
my_df[i,"channelTitle"] <- res[i,"channelTitle"]
#my_df[i,"thumbnails.high.url"] <- res[i,"thumbnails.high.url"]
#my_df[i,"link"] <-paste("https://www.youtube.com/watch?v=",v_id,sep="")
}
#Convert thumbnail to vid links
#https://www.youtube.com/watch?v=pjJgCXx_FRk
#convert to numeric
my_df <- transform(my_df, viewcount = as.numeric(viewcount),
likecount = as.numeric(likecount),
dislikecount=as.numeric(dislikecount))
#Order desc by viewcount,likecount, asc dislikecount
my_df <-my_df[order(-my_df[,2],-my_df[,3],my_df[,4]),]
#my_df <- my_df[,-c(8,9,10)]
#
# v_id<-  res[1,"video_id"]
# video_stats <- get_stats(video_id=v_id)
#
# my_df[1,] <- data.frame(matrix(unlist(video_stats), nrow=1, byrow=TRUE),stringsAsFactors=FALSE)
#
# video_stats
#View(my_df)
#nrow(res)
#save this in a file
setDT(my_df)
saveRDS(my_df, "data/dt.RDS")
runApp()
for ( i in 1:nrow(my_df)) {
my_df[i,"link"] <-paste("https://www.youtube.com/watch?v=",v_id,sep="")
}
View(my_df)
#nrow(res)
for ( i in 1:nrow(my_df)) {
v_id <- my_df[i,vid]
my_df[i,"link"] <-paste("https://www.youtube.com/watch?v=",v_id,sep="")
}
my_df[1,"vid"]
#nrow(res)
for ( i in 1:nrow(my_df)) {
v_id <- my_df[i,"vid"]
my_df[i,"link"] <-paste("https://www.youtube.com/watch?v=",v_id,sep="")
}
runApp()
?yt_search()
s_text="Paneer Butter Masala"
res <- yt_search(s_text,order=viewCount)
s_text="Paneer Butter Masala"
res <- yt_search(s_text)
View(res)
my_df<- data.frame(vid=character(),
viewcount=integer(),
likecount=integer(),
dislikecount=integer(),
favouritecount=integer(),
commentcount=integer())
my_df["title"] <- as.character()
my_df["description"] <- as.character()
my_df["publishTime"] <- as.character()
my_df["channelTitle"] <- as.character()
#my_df["thumbnails.high.url"] <- as.character()
my_df["link"] <- as.character()
my_df["overall_positive_score"]<- as.integer()
my_df["overall_negative_score"]<- as.integer()
my_df["overall_neutral_score"]<- as.integer()
my_df["viewcount"]<- as.integer()
my_df["likecount"]<- as.integer()
my_df["dislikecount"]<- as.integer()
#print("after my_df")
for (i in 1:nrow(res)) {
#For each video, get the rating,view count
# print(paste(i,"in loop"))
v_id <-  res[i,"video_id"]
video_stats <- get_stats(video_id=v_id)
my_df[i,1:6] <- data.frame(matrix(unlist(video_stats), nrow=1, byrow=TRUE),stringsAsFactors=FALSE)
my_df[i,"title"] <- res[i,"title"]
my_df[i,"description"] <- res[i,"description"]
my_df[i,"channelId"] <- res[i,"channelId"]
my_df[i,"publishTime"] <- res[i,"publishTime"]
my_df[i,"channelTitle"] <- res[i,"channelTitle"]
#my_df[i,"thumbnails.high.url"] <- res[i,"thumbnails.high.url"]
my_df[i,"link"] <-paste("https://www.youtube.com/watch?v=",v_id,sep="")
}
s_text="Paneer Butter Masala"
res <- yt_search(term=s_text)
#https://cran.r-project.org/web/packages/tuber/vignettes/tuber-ex.html
my_df<- data.frame(vid=character(),
viewcount=integer(),
likecount=integer(),
dislikecount=integer(),
favouritecount=integer(),
commentcount=integer())
my_df["title"] <- as.character()
my_df["description"] <- as.character()
my_df["publishTime"] <- as.character()
my_df["channelTitle"] <- as.character()
#my_df["thumbnails.high.url"] <- as.character()
my_df["link"] <- as.character()
my_df["overall_positive_score"]<- as.integer()
my_df["overall_negative_score"]<- as.integer()
my_df["overall_neutral_score"]<- as.integer()
my_df["viewcount"]<- as.integer()
my_df["likecount"]<- as.integer()
my_df["dislikecount"]<- as.integer()
#print("after my_df")
# url = paste(URL_base, allids[[i]], URL_details, URL_key, sep = "")
#nrow(res)
for (i in 1:nrow(res)) {
#For each video, get the rating,view count
# print(paste(i,"in loop"))
v_id <-  res[i,"video_id"]
video_stats <- get_stats(video_id=v_id)
my_df[i,1:6] <- data.frame(matrix(unlist(video_stats), nrow=1, byrow=TRUE),stringsAsFactors=FALSE)
my_df[i,"title"] <- res[i,"title"]
my_df[i,"description"] <- res[i,"description"]
my_df[i,"channelId"] <- res[i,"channelId"]
my_df[i,"publishTime"] <- res[i,"publishTime"]
my_df[i,"channelTitle"] <- res[i,"channelTitle"]
#my_df[i,"thumbnails.high.url"] <- res[i,"thumbnails.high.url"]
my_df[i,"link"] <-paste("https://www.youtube.com/watch?v=",v_id,sep="")
}
#Convert thumbnail to vid links
#https://www.youtube.com/watch?v=pjJgCXx_FRk
#convert to numeric
my_df <- transform(my_df, viewcount = as.numeric(viewcount),
likecount = as.numeric(likecount),
dislikecount=as.numeric(dislikecount))
#Order desc by viewcount,likecount, asc dislikecount
my_df <-my_df[order(-my_df[,2],-my_df[,3],my_df[,4]),]
#my_df <- my_df[,-c(8,9,10)]
#
# v_id<-  res[1,"video_id"]
# video_stats <- get_stats(video_id=v_id)
#
# my_df[1,] <- data.frame(matrix(unlist(video_stats), nrow=1, byrow=TRUE),stringsAsFactors=FALSE)
#
# video_stats
#View(my_df)
View(my_df)
library(tuber)
library(tidyverse)
library(lubridate)
library(stringi)
library(wordcloud)
library(gridExtra)
#save this in a file
setDT(my_df)
saveRDS(my_df, "data/dt.RDS")
# = Channel stats = #
#Hebbars Kitchen
chstat = get_channel_stats("UCPPIsrNlEkaFQBk-4uNkOaw")
videos = yt_search(term="", type="video", channel_id = "UCbZRdTukTCjFan4onn04sDA")
videos = videos %>%
mutate(date = as.Date(publishedAt)) %>%
filter(date > "2016-01-01") %>%
arrange(date)
# = Videos = #
videos = yt_search(term="", type="video", channel_id = "UCPPIsrNlEkaFQBk-4uNkOaw")
videos = videos %>%
mutate(date = as.Date(publishedAt)) %>%
filter(date > "2016-01-01") %>%
arrange(date)
# = Comments = #
comments = lapply(as.character(videos$video_id), function(x){
get_comment_threads(c(video_id = x), max_results = 1000)
})
comments = lapply(as.character(videos$video_id), function(x){
get_comment_threads(c(video_id = x), max_results = 1000)
})
# = Prep the data = #
# = Video Stat Table = #
videostats = lapply(as.character(videos$video_id), function(x){
get_stats(video_id = x)
})
videostats = do.call(rbind.data.frame, videostats)
videostats$title = videos$title
videostats$date = videos$date
videostats = select(videostats, date, title, viewCount, likeCount, dislikeCount, commentCount) %>%
as.tibble() %>%
mutate(viewCount = as.numeric(as.character(viewCount)),
likeCount = as.numeric(as.character(likeCount)),
dislikeCount = as.numeric(as.character(dislikeCount)),
commentCount = as.numeric(as.character(commentCount)))
